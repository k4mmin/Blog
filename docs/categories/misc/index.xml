<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Misc on Kammin</title>
    <link>https://k4mmin.github.io/blog/categories/misc/index.xml</link>
    <description>Recent content in Misc on Kammin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://k4mmin.github.io/blog/categories/misc/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Web scrapping with python</title>
      <link>https://k4mmin.github.io/blog/post/Web-scrapping-Redmine/</link>
      <pubDate>Tue, 03 Jul 2018 23:12:04 +0200</pubDate>
      
      <guid>https://k4mmin.github.io/blog/post/Web-scrapping-Redmine/</guid>
      <description>

&lt;h2 id=&#34;web-scrapping-redmine-activity&#34;&gt;Web scrapping Redmine activity&lt;/h2&gt;

&lt;h3 id=&#34;what&#34;&gt;what?&lt;/h3&gt;

&lt;p&gt;Ejemplo de web scrapping en una web con https y atenticación usando python y xpath&lt;/p&gt;

&lt;p&gt;Vamos a hacer login en redmine, recojer la session  y recorrer el html de la pestaña actividad de redmine para obtener los tickets sobre los que imputar las horas y lanzarlos en pestañas del navegador.&lt;/p&gt;

&lt;h3 id=&#34;why&#34;&gt;why?&lt;/h3&gt;

&lt;p&gt;Un dia normal de curro. Tareas por aquí, correos por ayá, miro la hora y hay que imputar el tiempo de las tareas realizadas. ¿Es que eso no puede hacerlo otro?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://k4mmin.github.io/blog/static/images/homer_for_president.jpg&#34; alt=&#34;Simspsons&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Para facilitar el registro diario de horas en redmine voy a crear un pequeño script para ahorrar algo de tiempo y de camino repasar algunos conceptos como el uso de xpath.&lt;/p&gt;

&lt;p&gt;Cuando tengo un rato libre le doy un repaso a la &lt;a href=&#34;http://www.redmine.org/projects/redmine/wiki/Rest_api&#34;&gt;api de redmine&lt;/a&gt; pero en este caso no podemos acceder a la pestaña actividad desde esta. Si no existe la herramienta pues la creamos. Why not?&lt;/p&gt;

&lt;h3 id=&#34;how&#34;&gt;How?&lt;/h3&gt;

&lt;p&gt;Para realizar web scrapping el primer paso es ir a la página para comprobar dónde está la información que queremos obtener y en nuestro caso cómo es el proceso que lleva a esta. Tenemos una página con autenticación y https. Los pasos que tiene que seguir el programa son:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Obtener el html de la página de login con una peticion GET&lt;/li&gt;
&lt;li&gt;Mandar en una petición POST el formulario de login relleno&lt;/li&gt;
&lt;li&gt;Una vez realizado el login correctamente guardar las cookies de la sesión generada en el sitio&lt;/li&gt;
&lt;li&gt;Realizar las consultas a la página con peticiones GET que contenga la información con los datos de la sesión obtenidas&lt;/li&gt;
&lt;li&gt;Tratar esa información&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Estos tres primeros pasos podemos resumirlos si queremos centrarnos en el scrapping haciendo uso de las herramientas de desarrolladores de los navegadores Chrome o Firefox. Si hacemos login manualmente en la página desde la pestaña &amp;lsquo;Network&amp;rsquo; del navegador podemos obtener las cookies de sesión en forma de consulta curl y lanzarla en python con la librería &amp;lsquo;os&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://k4mmin.github.io/blog/static/images/Chrome.png&#34; alt=&#34;curl&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;curl=&#39;&#39;&#39;curl &#39;https://redmine.empresa.com/activity?&amp;amp;show_issues=1&amp;amp;user_id=3333&#39; -H &#39;User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Mobile Safari/537.36&#39; -H &#39;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#39; -H &#39;Cache-Control: max-age=0&#39; -H &#39;Cookie: _redmine_session=BAh7Ckkimuchasletrasynumerosdemaneraaleatoria946d49c7&#39; -H &#39;Connection: keep-alive&#39; --compressed --cacert certificate.pem &amp;gt; redmine_activity.html&#39;&#39;&#39;

os.system(curl)

with open(r&#39;redmine_activity.html&#39;,&#39;r&#39;) as file:
    page = file.read()
tree = lxml.html.fromstring(page)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Usando la librería &amp;lsquo;requests&amp;rsquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests, lxml.html

login_url=&#39;https://redmine.empresa.com/login&#39;
cert=&#39;certificate.pem&#39;
username=&#39;MiUsuario&#39;
password=&#39;MiContraseña&#39;

# hacer login y obtener la sesión con las cookies necesarias
def request_session(login_url,username,password,cert):
    session = requests.session()
    try:
        login = session.get(login_url, verify=cert)
    except requests.exceptions.RequestException as e:
        print e
        return none
    login_html = lxml.html.fromstring(login.text)
    hidden_inputs = login_html.xpath(r&#39;//form//input[@type=&amp;quot;hidden&amp;quot;]&#39;)
    form = {x.attrib[&amp;quot;name&amp;quot;]: x.attrib[&amp;quot;value&amp;quot;] for x in hidden_inputs}
    form[&#39;username&#39;] = username
    form[&#39;password&#39;] = password
    try:
        response = session.post(login_url, verify=cert, data=form)
        print response.status_code
        if response.status_code == 200:
            return session
    except requests.exceptions.RequestException as e:
        print e
        return none

s=request_session(login_url,username,password,cert)

# consulta de la página específica con la información a tratar
payload = {&#39;show_issues&#39;: &#39;1&#39;, &#39;user_id&#39;: &#39;1605&#39;}
r = s.get(&#39;https://redmine.empresa.com/activity&#39;, params=payload, verify=&#39;certificate.pem&#39;)

# In [26]: print r.status_code
# 200

tree = lxml.html.fromstring(r.text)
activity = tree.xpath(&#39;//div[@id]/h3|//dl&#39;)

question = raw_input(&amp;quot;open today&#39;s tasks in firefox?: [y/n]&amp;quot;)
if question == &#39;y&#39;:
    firefox=True

tasks_list=[]
for day in activity:
    if day.tag == &#39;h3&#39;:
        day_text = day.text
        # print day_text
    elif day.tag == &#39;dl&#39;:
        tasks = day.findall(&amp;quot;dt[@class=&#39;issue-edit  me&#39;]/a&amp;quot;)
        # print tasks
        for task in tasks:
            task_text = task.text
            # print task_text
            task_url = &#39;https://redmine.empresa.com&#39;+str(task.attrib)[10:-2]
            # print task_url
            if day_text == &#39;Hoy&#39; and firefox:
                # print task_url
                tasks_list.append(task_url)

if question == &#39;y&#39;:
  for elem in set(tasks_list):
    os.system(&#39;firefox %s&#39; %(elem))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Con esto se abre en pestañas de firefox todos los tickets que hemos modificado hoy.
A partir de aquí podemos ir explorando funcionalidades u otras partes de la web, por ejemplo abrir directamente la página donde imputar las horas (es necesario obtener el html de las urls del paso anterior)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re

for elem in tasks_list:
  r = s.get(elem, verify=&#39;certificate.pem&#39;)
  tree = lxml.html.fromstring(r.text)
  parent_task = tree.xpath(&#39;&#39;&#39;//div[@id=&#39;relations&#39;]/form/table[@class=&amp;quot;list issues&amp;quot;]/tr/td[@class=&#39;subject&#39;]/a&#39;&#39;&#39;)
  # extraer numeros de un string a una lista con expresiones regulares
  task_num = map(int, re.findall(&#39;\d+&#39;, parent_task[0].text))

  url = &#39;https://redmine.empresa.com/issues/%d/time_entries/new&#39; %(task_num[0])
  os.system(&#39;firefox %s&#39; %(url))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Y eso es todo, próximamente comentaré un poco la sintaxis de xpath y refactorizaré el código python que pueda volver a necesitar.&lt;/p&gt;

&lt;h3 id=&#34;notas&#34;&gt;Notas&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Certificados&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dependiendo del certificado usado por el sitio web nos devolverá este error o no.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;SSLError: HTTPSConnectionPool(host=&#39;redmine.empresa.com&#39;, port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(1, u&#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)&#39;),))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Muchos certificados usados por los navegadores no están disponibles en el sistema (para usar estos en request exportar REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt). En este caso la solución fué descargar los certificados desde el navegador web y crear una cadena de certificados con ellos.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://k4mmin.github.io/blog/static/images/certs.png&#34; alt=&#34;certificados&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat COMODO.ca COMODO.ca2 &amp;gt; certificate.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Curl request&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Para usar la consulta curl obtenida desde las &amp;lsquo;developers tools&amp;rsquo; he tenido que añadir al final el certificado con &amp;lsquo;&amp;ndash;cacert certificado.pem&amp;rsquo; y eliminar algunos headers.&lt;/p&gt;

&lt;h3 id=&#34;referencias-usadas&#34;&gt;Referencias usadas&lt;/h3&gt;

&lt;p&gt;De mi profesor &lt;a href=&#34;https://twitter.com/Pledin_JD&#34;&gt;@Pledin_JD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.josedomingo.org/pledin/2015/01/trabajar-con-ficheros-xml-desde-python_1/&#34;&gt;https://www.josedomingo.org/pledin/2015/01/trabajar-con-ficheros-xml-desde-python_1/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sobre Xpath&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://xpather.com/&#34;&gt;http://xpather.com/&lt;/a&gt;
&lt;a href=&#34;http://xmltoolbox.appspot.com/xpath_generator.html&#34;&gt;http://xmltoolbox.appspot.com/xpath_generator.html&lt;/a&gt;
&lt;a href=&#34;https://www.w3schools.com/xml/xpath_syntax.asp&#34;&gt;https://www.w3schools.com/xml/xpath_syntax.asp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Python request con autenticación&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://brennan.io/2016/03/02/logging-in-with-requests/&#34;&gt;https://brennan.io/2016/03/02/logging-in-with-requests/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://k4mmin.github.io/blog/about/</link>
      <pubDate>Sat, 23 Jun 2018 13:33:53 +0200</pubDate>
      
      <guid>https://k4mmin.github.io/blog/about/</guid>
      <description>&lt;p&gt;this is me.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>hello Hugo</title>
      <link>https://k4mmin.github.io/blog/post/hello-Hugo/</link>
      <pubDate>Sat, 23 Jun 2018 13:33:04 +0200</pubDate>
      
      <guid>https://k4mmin.github.io/blog/post/hello-Hugo/</guid>
      <description>&lt;p&gt;prueba de nuevo post&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>